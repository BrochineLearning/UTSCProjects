{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the TSNE features on XGBoost \n",
    "\n",
    "The following TSNE reductions were generated by first using TruncatedSVD to get them to 50 features and then reduced down to several variations. \n",
    "\n",
    "In the first cell first the LC reductions are concatenated to the combined feature file and tested on the XGBoost default parameters, in the second cell the PCA features are first removed. \n",
    "\n",
    "The highest score achieved was found when concatenating 3D reduction of phase_space giving a score of 0.715170838132. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the base score on the combined dataset is: 0.699410990974\n",
      "Conatenating 2D reduction of LC\n",
      "0.692151844713\n",
      "Conatenating 3D reduction of LC\n",
      "0.715170838132\n",
      "Conatenating 10D reduction of LC\n",
      "0.686163523958\n",
      "Conatenating 20D reduction of LC\n",
      "0.708888928806\n",
      "Concatenating 2D reduction of phase_space\n",
      "0.699410990974\n",
      "Concatenating 3D reduction of phase_space\n",
      "0.699410990974\n",
      "Concatenating 10D reduction of phase_space\n",
      "0.699410990974\n",
      "Concatenating 20D reduction of phase_space\n",
      "0.699410990974\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "# these are the various reduction files \n",
    "\n",
    "tend_LC = pd.read_csv('tend_LC.csv', header=0, index_col =0)\n",
    "tend_phase = pd.read_csv('tend_phase.csv', header=0, index_col=0)\n",
    "\n",
    "threed_LC = pd.read_csv('threed_LC.csv', header=0, index_col=0)\n",
    "threed_phase = pd.read_csv('threed_phase.csv', header=0, index_col=0)\n",
    "\n",
    "twentyd_LC = pd.read_csv('twentyd_LC.csv', header=0, index_col=0)\n",
    "twentyd_phase = pd.read_csv('twentyd_phase.csv', header=0, index_col=0)\n",
    "\n",
    "twod_LC = pd.read_csv('twod_LC.csv', header=0, index_col=0)\n",
    "twod_phase = pd.read_csv('twod_phase.csv', header=0, index_col=0)\n",
    "\n",
    "reductions_LC = [twod_LC, threed_LC, tend_LC, twentyd_LC]\n",
    "reductions_phase = [twod_phase, threed_phase, tend_phase, twentyd_phase]\n",
    "\n",
    "# opening the combined feature file  \n",
    "\n",
    "data_combined_features = pd.read_csv(\"TESSfield_05h_01d_combinedfeatures.csv\",\n",
    "                                     header=0, index_col=0)\n",
    "data_combined_features = data_combined_features.drop(data_combined_features.index[-1])\n",
    "\n",
    "# drop the columns that aren't features and get targets \n",
    "X = data_combined_features.drop(['Ids', 'CatalogY', 'ManuleY', 'CombinedY',\n",
    "                                 'Catalog_Period', 'Depth', 'Catalog_Epoch', 'SNR'],\n",
    "                                axis=1)\n",
    "\n",
    "y = data_combined_features['CombinedY']\n",
    "\n",
    "\n",
    "def modelfit(alg, X, y, cv_folds=4):\n",
    "    # StratifiedKFold automatically used by cross_val_predict on binary classification\n",
    "    # bear in mind that this does not use trapezfoid rule\n",
    "    # y_pred calculates the probabilities that each value is 1 or 0 using stratified cross validation\n",
    "    # pr_auc calculates the area under a precision recall curve\n",
    "    y_pred = cross_val_predict(alg, X, y, cv=cv_folds)\n",
    "    pr_auc = metrics.average_precision_score(y, y_pred)\n",
    "    return pr_auc\n",
    "\n",
    "xgb1 = XGBClassifier(objective='binary:logistic')\n",
    "\n",
    "print 'the base score on the combined dataset is: {0}'.format(modelfit(xgb1, X, y))\n",
    "\n",
    "for reductions in reductions_LC:\n",
    "    combination = pd.concat([reductions, X], axis=1)\n",
    "    print 'Conatenating {0}D reduction of LC'.format(len(reductions.columns))\n",
    "    print modelfit(xgb1, combination, y)\n",
    "    \n",
    "for reductions in reductions_phase:\n",
    "    reductions = reductions.drop(reductions.index[-1]) # need to drop last to make files line up\n",
    "    print 'Concatenating {0}D reduction of phase_space'.format(len(reductions.columns))\n",
    "    combination = pd.concat([reductions, X], axis=1)\n",
    "#     print combination.columns\n",
    "\n",
    "#      print '{0}'.format(combination.columns)\n",
    "    print modelfit(xgb1, combination, y)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.715170838132\n"
     ]
    }
   ],
   "source": [
    "threed_LC = threed_LC.drop(reductions.index[-1])\n",
    "\n",
    "combination = pd.concat([threed_LC, X], axis=1)\n",
    "\n",
    "print modelfit(xgb1, combination, y)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, simply concatenating the light curve reduction to 3D creates a default score increase. \n",
    "\n",
    "Next we'll see if substituting TSNE for the PCA features causes a better score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'BLS_Period_1_0', u'BLS_Tc_1_0', u'BLS_SN_1_0', u'BLS_SR_1_0',\n",
      "       u'BLS_SDE_1_0', u'BLS_Depth_1_0', u'BLS_Qtran_1_0', u'BLS_Qingress_1_0',\n",
      "       u'BLS_OOTmag_1_0', u'BLS_i1_1_0', u'BLS_i2_1_0', u'BLS_deltaChi2_1_0',\n",
      "       u'BLS_fraconenight_1_0', u'BLS_Npointsintransit_1_0',\n",
      "       u'BLS_Ntransits_1_0', u'BLS_Npointsbeforetransit_1_0',\n",
      "       u'BLS_Npointsaftertransit_1_0', u'BLS_Rednoise_1_0',\n",
      "       u'BLS_Whitenoise_1_0', u'BLS_SignaltoPinknoise_1_0'],\n",
      "      dtype='object')\n",
      "Conatenating 2D reduction of LC\n",
      "0.695744191453\n",
      "Conatenating 3D reduction of LC\n",
      "0.696485691649\n",
      "Conatenating 10D reduction of LC\n",
      "0.699465888822\n",
      "Conatenating 20D reduction of LC\n",
      "0.682142719986\n",
      "Concatenating 2D reduction of phase_space\n",
      "0.698922212224\n",
      "Concatenating 3D reduction of phase_space\n",
      "0.698922212224\n",
      "Concatenating 10D reduction of phase_space\n",
      "0.698922212224\n",
      "Concatenating 20D reduction of phase_space\n",
      "0.698922212224\n"
     ]
    }
   ],
   "source": [
    "# performing the same but dropping the PCA features\n",
    "\n",
    "X = X.drop(X.columns[20:], axis=1)\n",
    "\n",
    "print X.columns # making sure columns are dropped\n",
    "\n",
    "for reductions in reductions_LC:\n",
    "    combination = pd.concat([reductions, X], axis=1)\n",
    "    print 'Conatenating {0}D reduction of LC'.format(len(reductions.columns))\n",
    "    print modelfit(xgb1, combination, y)\n",
    "    \n",
    "for reductions in reductions_phase:\n",
    "    reductions = reductions.drop(reductions.index[-1]) # need to drop last to make files line up\n",
    "    print 'Concatenating {0}D reduction of phase_space'.format(len(reductions.columns))\n",
    "    combination = pd.concat([reductions, X], axis=1)\n",
    "    print modelfit(xgb1, combination, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see, just having the BLS features together with the TSVD/TSNE reduction does not imporove the score and in some cases reduces it, but concatenating the 3D reduction of the LC does increase the score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py27]",
   "language": "python",
   "name": "conda-env-py27-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
