{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GBC Replication\n",
    "\n",
    "The following notebook will attemp to use GBC and partial dependance plots to explain the features used in the paper:https://arxiv.org/pdf/1610.05359v2.pdf In which XGBoost Classifier was trained to recognize whether tightly packed planetary systems were stable or not. \n",
    "\n",
    "To do this the Gradient Boosting Classifier will be tuned to mimic the scores the author obtained and then utilize  the Partial Dependance Plot functions which can demonstrate the interactions between features of a Boosted Tree based classifier; this is nessissary as XGBoost is not compatible with the current sklearn partial dependance plot  implementation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import cross_validation, metrics   #Additional scklearn functions\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "trainData = pd.read_csv('1e7data_train.csv', index_col=0)\n",
    "testData = pd.read_csv('1e7data_holdout.csv', index_col=0)\n",
    "df = trainData\n",
    "dftest = testData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features = []\n",
    "features += ['daOverRH1', 'daOverRH2']\n",
    "features += ['mindaOverRH', 'maxdaOverRH']\n",
    "features += ['norm_std_a1', 'norm_max_a1', 'norm_std_window10_a1', 'norm_max_window10_a1']\n",
    "features += ['norm_std_a2', 'norm_max_a2', 'norm_std_window10_a2', 'norm_max_window10_a2']\n",
    "features += ['norm_std_a3', 'norm_max_a3', 'norm_std_window10_a3', 'norm_max_window10_a3']\n",
    "features += ['avg_ecross1', 'std_ecross1', 'max_ecross1', 'min_ecross1']\n",
    "features += ['avg_ecross2', 'std_ecross2', 'max_ecross2', 'min_ecross2']\n",
    "features += ['avg_ecross3', 'std_ecross3', 'max_ecross3', 'min_ecross3']\n",
    "features += ['norm_a1_slope', 'norm_a2_slope', 'norm_a3_slope']\n",
    "features += ['norm_LyapunovTime']\n",
    "\n",
    "\n",
    "X_train = df[features]\n",
    "\n",
    "y_train = df['Stable']\n",
    "X_test = dftest[features]\n",
    "\n",
    "X_train = X_train.replace(np.nan, -999)\n",
    "X_train = X_train.replace(np.inf, -999)\n",
    "\n",
    "X_test = X_test.replace(np.nan, -999)\n",
    "X_test = X_test.replace(np.inf, -999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Report\n",
      "Accuracy : 0.882\n",
      "AUC Score (Test): 0.895542\n",
      "ROC_AUC_Score:  0.945628156566\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "model = GradientBoostingClassifier(loss='deviance', learning_rate=0.002, n_estimators=5000,\n",
    "                                  subsample=.5,  min_samples_split=2, \n",
    "                                  min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_depth=8,\n",
    "                                  init=None, random_state=42, \n",
    "                                  max_leaf_nodes=8, warm_start=False, max_features=.5)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "dtest_predictions = model.predict(X_test) \n",
    "dtest_predprob = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "#Print model report:\n",
    "print \"\\nModel Report\"\n",
    "print \"Accuracy : %.4g\" % metrics.accuracy_score(dftest['Stable'].values, dtest_predictions)\n",
    "print \"AUC Score (Test): %f\" % metrics.average_precision_score(dftest['Stable'], dtest_predprob)\n",
    "print 'ROC_AUC_Score: ', metrics.roc_auc_score(dftest['Stable'], dtest_predprob)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Report\n",
      "Accuracy : 0.89\n",
      "AUC Score (Test): 0.901043\n",
      "ROC_AUC_Score:  0.949938574939\n"
     ]
    }
   ],
   "source": [
    "import xgboost\n",
    "from xgboost.sklearn import XGBClassifier \n",
    "\n",
    "model0 = XGBClassifier(colsample_bylevel=1, colsample_bytree=1,\n",
    "                         n_estimators=5000, gamma=0,\n",
    "                         max_delta_step=0, missing=None, \n",
    "                         reg_alpha=0, reg_lambda=1,\n",
    "                         scale_pos_weight=1, seed=27,\n",
    "                        learning_rate=.002, max_depth=8,\n",
    "                        subsample=.5, min_child_weight=1.2, \n",
    "                        objective='binary:logistic', nthread=-1)\n",
    "\n",
    "model0.fit(X_train, y_train)\n",
    "\n",
    "dtest_predictions = model0.predict(X_test) \n",
    "dtest_predprob = model0.predict_proba(X_test)[:, 1]\n",
    "\n",
    "#Print model report:\n",
    "print \"\\nModel Report\"\n",
    "print \"Accuracy : %.4g\" % metrics.accuracy_score(dftest['Stable'].values, dtest_predictions)\n",
    "print \"AUC Score (Test): %f\" % metrics.average_precision_score(dftest['Stable'], dtest_predprob)\n",
    "print 'ROC_AUC_Score: ', metrics.roc_auc_score(dftest['Stable'], dtest_predprob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that GBC has been tuned to mimic XGBoost we can formulate PDP. "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py27]",
   "language": "python",
   "name": "conda-env-py27-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
