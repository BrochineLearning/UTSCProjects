{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# TSFRESH Features Applied to XGBoosts's fitting of the TESS simulated dataset.\n",
    "\n",
    "The following notebook uses the TSFRESH software for feature extraction from time series data. Documentation can be found at: \n",
    "\n",
    "The following implementation steps are taken: \n",
    "\n",
    "1) Data is imported and converted to a column based time series instead of row based time series\n",
    "\n",
    "2) The features are extracted \n",
    "\n",
    "3) XGBoost on defualt parameters is trained using the data set\n",
    "\n",
    "4) The features are concatenated to the Combined_Features files and then used to train XGBoost to see \n",
    "the impact they have on the score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import relevant modules \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# open Chelsea's combined feature file\n",
    "# remove the last row to make the dimensions match with the raw LC file\n",
    "data_combined_features = pd.read_csv(\"TESSfield_05h_01d_combinedfeatures.csv\", header=0, index_col = 0)\n",
    "data_combined_features = data_combined_features.drop(data_combined_features.index[-1])\n",
    "\n",
    "# drop the columns that aren't features\n",
    "X = data_combined_features.drop(['Ids', 'CatalogY', 'ManuleY', 'CombinedY',\n",
    "                                 'Catalog_Period', 'Depth', 'Catalog_Epoch', 'SNR'],\n",
    "                                axis=1)\n",
    "\n",
    "# get the target values \n",
    "# In order to get the index of Y to match with X \n",
    "# we need to add one to the values \n",
    "y = pd.Series()\n",
    "y = data_combined_features['CombinedY']\n",
    "y.index = y.index + 1\n",
    "\n",
    "# load the raw light curve data file to get the time series information\n",
    "# delete the first row (which only contains NaN values)\n",
    "data = np.load(\"TESSfield_05h_01d.npy\")\n",
    "data_raw = np.delete(data, (0), axis=0)\n",
    "\n",
    "\n",
    "# tsfresh's algorithm takes a pandas DataFrame so \n",
    "# we convert the npy array\n",
    "# we also needs the ID's for tsfresh \n",
    "df_raw = pd.DataFrame(data_raw)\n",
    "df_raw['Ids'] = data_combined_features['Ids']\n",
    "\n",
    "# the following initiates a column based time series \n",
    "for i, j in enumerate(df_raw['Ids']):\n",
    "    if i == 0:\n",
    "        temp = [[j]]*(len(df_raw.columns) - 1)\n",
    "    else:\n",
    "        temp += [[j]]*(len(df_raw.columns) - 1)\n",
    "\n",
    "\n",
    "# we initiate the dataframe of the ID values we just created\n",
    "df_raw_transpose = pd.DataFrame(temp, columns=['Ids'])\n",
    "\n",
    "# the time series data now needs to be transposed to progress down the column\n",
    "# so we retrieve each value in a linear list instead of an array\n",
    "vals = []\n",
    "for rows in data_raw:\n",
    "    for values in rows:\n",
    "        vals.append(values)\n",
    "\n",
    "# we now add the transformed series data to the pandas dataframe we just created\n",
    "df_raw_transpose['x'] = vals\n",
    "time = range(0, 480)*len(data_raw)\n",
    "df_raw_transpose['time'] = time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tom/anaconda3/envs/py27/lib/python2.7/site-packages/pandas/computation/expressions.py:182: UserWarning: evaluating in Python space because the '*' operator is not supported by numexpr for the bool dtype, use '&' instead\n",
      "  unsupported[op_str]))\n"
     ]
    }
   ],
   "source": [
    "# the following is the implementation of the tsfresh algorithm\n",
    "from tsfresh import extract_features\n",
    "from tsfresh import select_features\n",
    "from tsfresh.utilities.dataframe_functions import impute\n",
    "\n",
    "extracted_features = extract_features(df_raw_transpose, column_id=\"Ids\",\n",
    "                                      column_sort=\"time\")\n",
    "\n",
    "# impute removes any features that only contain NaN \n",
    "impute(extracted_features)\n",
    "# features filtered removes features that aren't statistically significant \n",
    "# and puts them in format that allows them to be used for training\n",
    "features_filtered = select_features(extracted_features, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It total it finds a total of 113 features, a preview of some of the features are: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([                                             u'x__skewness',\n",
      "                                                    u'x__kurtosis',\n",
      "                               u'x__ar_coefficient__k_10__coeff_1',\n",
      "                                            u'x__count_above_mean',\n",
      "                                            u'x__count_below_mean',\n",
      "                                 u'x__binned_entropy__max_bins_10',\n",
      "                                      u'x__autocorrelation__lag_1',\n",
      "                                      u'x__autocorrelation__lag_2',\n",
      "                                        u'x__mean_autocorrelation',\n",
      "                                   u'x__longest_strike_below_mean',\n",
      "       ...\n",
      "                    u'x__time_reversal_asymmetry_statistic__lag_3',\n",
      "       u'x__cwt_coefficients__widths_(2, 5, 10, 20)__coeff_9__w_2',\n",
      "                               u'x__ar_coefficient__k_10__coeff_3',\n",
      "                   u'x__mean_abs_change_quantiles__qh_0.2__ql_0.0',\n",
      "                   u'x__mean_abs_change_quantiles__qh_0.8__ql_0.0',\n",
      "                   u'x__mean_abs_change_quantiles__qh_0.4__ql_0.2',\n",
      "                                    u'x__last_location_of_maximum',\n",
      "                                   u'x__first_location_of_maximum',\n",
      "                   u'x__mean_abs_change_quantiles__qh_0.6__ql_0.2',\n",
      "                                    u'x__fft_coefficient__coeff_1'],\n",
      "      dtype='object', length=113)\n"
     ]
    }
   ],
   "source": [
    "print features_filtered.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now take the extracted features and use them to train the algo, first we'll do it\n",
    "without the combined features and then we'll append them together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pr_auc model score: 0.602695503001\n"
     ]
    }
   ],
   "source": [
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "# function to fit and get scores\n",
    "def modelfit(alg, X, y, cv_folds=4):\n",
    "\n",
    "    # StratifiedKFold automatically used by cross_val_predict on binary classification\n",
    "    # does not use trapezoid rule\n",
    "    # y_pred calculates the probabilities that each value is 1 or 0 using stratified cross validation \n",
    "    # pr_auc calculates the area under a precision recall curve \n",
    "    y_pred = cross_val_predict(alg, X, y, cv=cv_folds)\n",
    "    pr_auc = metrics.average_precision_score(y, y_pred)\n",
    "\n",
    "\n",
    "    # Print model report:\n",
    "    print \"pr_auc model score: {0}\".format(pr_auc)\n",
    "\n",
    "# initialize model and call fitting function\n",
    "xgb1 = XGBClassifier(\n",
    "    objective='binary:logistic')\n",
    "\n",
    "modelfit(xgb1, features_filtered, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now concatenate the two feature files together to see the effect it has. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pr_auc model score: 0.609236214129\n"
     ]
    }
   ],
   "source": [
    "X_concat = pd.concat([features_filtered, X], axis=1)\n",
    "X_concat = X_concat.drop([0]) # drop to make sure it aligns \n",
    "\n",
    "modelfit(xgb1, X_concat, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "In the next notebook I can try dropping some of the features like in the feature_selection notebook \n",
    "to see the effect it has on the score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py27]",
   "language": "python",
   "name": "conda-env-py27-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
